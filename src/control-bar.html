<head>
  <link rel="stylesheet" href="control-bar.css" />
</head>
<div class="control-bar drag-region">
  <button class="close-button" id="close-btn">
    <img src="icons/xmark.svg" alt="Close" />
  </button>
  <div class="border-l border-gray-500 h-6"></div>
  <button class="icon-button" id="select-window">
    <img src="icons/display.svg" alt="Entire Screen" />
  </button>
  <div class="border-l border-gray-500 h-6"></div>

  <div class="export-container">
    <div class="border-l border-gray-500 h-6"></div>
    <div>
      <button class="control-bar-btn" id="export-btn">Export To...</button>
    </div>
  </div>

  <div class="border-l border-gray-500 h-6"></div>
  <div style="display: flex; align-items: center;">
    <button class="control-bar-btn" id="record-btn">Record</button>
  </div>
</div>

<script>
  const {ipcRenderer} = require("electron");

  // Close button
  const closeButton = document.getElementById("close-btn");
  if (closeButton) {
    closeButton.addEventListener("click", () => {
      ipcRenderer.send("close-control-bar");
    });
  }

  // Export button
  const exportButton = document.getElementById("export-btn");
  if (exportButton) {
    exportButton.addEventListener("click", () => {
      ipcRenderer.send("export-to");
    });
  }

  // Select Window button
  const selectWindow = document.getElementById("select-window");
  const recordButton = document.getElementById("record-btn");
  let windowSelectedStatus = false;
  let selectedStream = null;

  if (selectWindow) {
    selectWindow.addEventListener("click", async () => {
      try {
        selectedStream = await navigator.mediaDevices.getDisplayMedia({video: true, audio: true});
        windowSelectedStatus = true;
        console.log("Window selected!");
      } catch (err) {
        console.error("Error selecting window:", err);
      }
    });
  }

  // Recording variables
  let captureInterval = null;
  let imageCapture = null;
  let capturedBlobs = [];
  let isRecording = false;

  function startRecording() {
    if (!windowSelectedStatus || !selectedStream) {
      showTooltip(recordButton, "Please select a capture area first.");
      return;
    }

    // Set up ImageCapture from selected stream
    const track = selectedStream.getVideoTracks()[0];
    imageCapture = new ImageCapture(track);

    // Clear any existing interval
    if (captureInterval) {
      clearInterval(captureInterval);
    }

    // Start capture loop
    captureInterval = setInterval(async () => {
      try {
        const bitmap = await imageCapture.grabFrame();

        // Draw to canvas
        const canvas = document.createElement("canvas");
        canvas.width = bitmap.width;
        canvas.height = bitmap.height;
        const ctx = canvas.getContext("2d");
        ctx.drawImage(bitmap, 0, 0);

        // Convert to PNG blob
        canvas.toBlob((blob) => {
          console.log("Captured frame for OCR!", blob);

          // Store blob as base64 for debug export
          const reader = new FileReader();
          reader.onloadend = () => {
            capturedBlobs.push({
              data: reader.result,
              mimeType: "image/png"
            });
          };
          reader.readAsDataURL(blob);
        }, "image/png");
      } catch (err) {
        console.error("Error grabbing frame:", err);
      }
    }, 1000);

    console.log("OCR capture loop started!");
    isRecording = true;
    updateRecordingUI();
  }

  async function stopRecording() {
    if (captureInterval) {
      clearInterval(captureInterval);
      captureInterval = null;
      console.log("OCR capture loop stopped.");
    }

    // Save frames if any were captured
    if (capturedBlobs.length > 0) {
      try {
        console.log(`Saving ${capturedBlobs.length} frames...`);
        const result = await ipcRenderer.invoke("save-recording-frames", capturedBlobs);
        if (result.success) {
          console.log(`Successfully saved ${result.files.length} frames to: ${result.directory}`);
          showTooltip(recordButton, `Saved ${result.files.length} frames to recordings folder`);
        }
      } catch (err) {
        console.error("Error saving frames:", err);
        showTooltip(recordButton, "Error saving frames. Check console.");
      }

      // Clear blobs array after saving
      capturedBlobs = [];
    }

    isRecording = false;
    updateRecordingUI();
  }

  function updateRecordingUI() {
    if (isRecording) {
      // Show stop state
      recordButton.classList.remove("fade-out");
      recordButton.textContent = "Stop";
      recordButton.classList.add("recording");

      // Disable select window button
      selectWindow.disabled = true;
      exportButton.disabled = true;
    } else {
      // Show record state with fade out animation
      recordButton.classList.add("fade-out");

      // Wait for animation to complete before changing text
      setTimeout(() => {
        recordButton.textContent = "Record";
        recordButton.classList.remove("recording", "fade-out");
      }, 150);

      // Enable select window button
      selectWindow.disabled = false;
      exportButton.disabled = false;
    }
  }

  // Record button toggle
  if (recordButton) {
    recordButton.addEventListener("click", () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    });
  }

  function showTooltip(targetElement, message) {
    let tooltip = document.createElement("div");
    tooltip.className = "tooltip";
    tooltip.innerText = message;
    document.body.appendChild(tooltip);

    // Position relative to the control bar
    const controlBar = document.querySelector(".control-bar");
    const rect = controlBar.getBoundingClientRect();

    tooltip.style.top = `${rect.top + rect.height / 2 - 55}px`;
    tooltip.style.left = `${rect.left + rect.width / 2 - tooltip.offsetWidth / 2}px`;
    tooltip.style.opacity = "1";

    setTimeout(() => {
      tooltip.style.opacity = "0";
      setTimeout(() => {
        tooltip.remove();
      }, 200);
    }, 2500);
  }

</script>